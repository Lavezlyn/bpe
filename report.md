# 实验报告
## BPE算法和Tokenizer训练流程概述
1. 初始化：
   - 将文本分割成基本单位（字符或字节）
   - 建立初始词汇表，包含所有基本单位

2. 迭代合并：
   - 统计所有相邻符号对的频率
   - 选择最高频的符号对合并为新符号
   - 将新符号添加到词汇表
   - 重复此过程直到达到目标词汇表大小或无法继续合并

### Tokenizer训练流程
1. 数据预处理：
   - 收集训练语料
   - 文本清洗（去除噪声、标准化等）
   - 添加特殊标记（如<|endoftext|>）

2. 基础词汇表构建：
   - 确定基本单位（UTF-8字节或Unicode字符）
   - 添加特殊token（如[PAD], [UNK], [CLS]等）
   - 统计基本单位的频率

3. BPE训练：
   - 设定目标词汇表大小
   - 执行BPE算法进行符号合并
   - 记录合并规则和最终词汇表

4. 验证和优化：
   - 在验证集上测试tokenization效果
   - 检查常见词组的切分结果
   - 调整特殊情况处理（如标点符号、数字等）

5. 保存和部署：
   - 保存词汇表和合并规则
   - 导出tokenizer配置
   - 实现encode和decode功能

## Our tokenizer vs GPT-2 tokenizer

### 英文文本的差异
GPT-2 tokenizer的token数量明显少于我们的实现，原因是：
- GPT-2使用了更大的训练语料，学习到了更多的常用词组组合
- GPT-2的BPE算法是在字节级别上操作的，而不是字符级别
- GPT-2的词汇表大小约为50,257，包含了大量常用词组
- 我们的实现是基于字符级别的，且词汇表较小
### 中文文本的差异
GPT-2 tokenizer会将中文文本分解成更多的token，原因是：
- GPT-2 tokenizer主要针对英文优化，对中文的支持较弱
- 每个中文字符都会被编码为多个字节
- 我们的实现直接将中文字符作为基本单位处理
### 具体token的差异
- GPT-2 tokenizer：能够识别常用英文词组，对数字和标点有特殊处理，中文字符会被编码为Unicode字节序列
- 我们的实现：英文会被分割成更小的单位，对中文字符的处理更直接，没有特殊的词组识别能力

## Tokenizer and LLM Quiz

### 1. Python字符与Unicode转换
- 使用`ord()`函数可以查看字符的Unicode编码
- 使用`chr()`函数可以将Unicode编码转换为字符

示例：
```python
print(ord('北'))  # 21271
print(ord('大'))  # 22823

print(chr(22823))  # 大
print(chr(27169))  # 模
print(chr(22411))  # 型
```

### 2. Tokenizer词汇表大小的权衡

大词汇表优势：
- 可以捕获更多的完整词组和常用表达
- 减少序列长度，因为更多词可以用单个token表示
- 可能提供更好的语义表示

大词汇表劣势：
- 模型参数量增加（embedding层和输出层变大）
- 训练时间更长
- 内存占用更多
- 可能出现数据稀疏问题

小词汇表优势：
- 模型更轻量，训练更快
- 内存占用更少
- 对罕见词有更好的泛化能力
- 训练更稳定

小词汇表劣势：
- 序列长度增加（需要更多token表示同样内容）
- 可能丢失一些语义信息
- 处理速度可能更慢（因为序列更长）

### 3. LLM无法处理简单字符串操作的原因
- LLM是基于统计模式的模型，不是按规则执行的程序
- 它们学习的是语言模式，而不是精确的算法操作
- 没有内置的字符串操作机制
- 训练数据中很少包含这类具体的操作示例

### 4. LLM在非英语语言上表现较差的原因
- 训练数据主要以英语为主
- 词汇表和分词策略主要针对英语优化
- 非英语语言（如日语）的语法结构和表达方式差异较大
- Unicode编码处理可能不够优化
- 上下文理解受限于文化差异

### 5. LLM在简单算术问题上表现不佳的原因
- LLM不是计算器，没有内置的数学运算能力
- 它们是通过模式匹配来"学习"数学，而不是真正理解数学运算
- 训练数据中的数学计算示例有限
- 位置编码可能影响数字的准确表示
- 缺乏精确的数值处理机制

### 6. GPT-2编写Python代码困难的原因
- GPT-2的训练数据中代码占比较小
- 代码需要精确的语法和逻辑，而LLM是基于概率的
- 缺乏对编程语言语法的严格约束
- 上下文窗口限制影响对长代码的理解
- 没有专门针对代码的训练优化

### 7. LLM遇到"<|endoftext|>"中断的原因
- 这是训练数据中用来标记文本结束的特殊token
- 模型被训练为在看到这个标记时停止生成
- 这是一个强烈的结束信号，类似于程序中的终止符
- 模型将其视为自然的结束点

### 8. LLM对"SolidGoldMagikarp"崩溃的原因
- 这可能是训练数据中的特殊标记或异常样本
- 模型可能将其识别为某种特殊含义
- 可能与训练过程中的数据处理方式有关
- 模型对特定字符组合产生了过度拟合

### 9. LLM更适合YAML而非JSON的原因
- YAML的语法更接近自然语言
- YAML的缩进结构更直观
- JSON的严格语法（如引号、逗号）更容易出错
- YAML更容易被模型理解和生成

### 10. LLM不是真正端到端语言建模的原因
- 需要tokenizer进行预处理
- 输入输出都需要经过token转换
- 实际处理的是token序列而不是原始文本
- 模型的理解受限于tokenization的质量
- 无法直接处理原始字符流